# ========== EMBEDDING CONFIG ==========
EMBEDDING_MODEL=sbert           # Options: sbert, titan

# ========== VECTOR STORE CONFIG ==========
VECTOR_DB=chroma                # Options: chroma, faiss, opensearch
CHROMA_PERSIST_DIR=./vectorstore/chroma_db

# ========== OPENSEARCH CONFIG ==========
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_INDEX=medical_docs

# ========== LLM CONFIG ==========
LLM_PROVIDER=bedrock            # Options: bedrock, hf
BEDROCK_MODEL=anthropic.claude-v2
HF_MODEL=google/flan-t5-large

# ========== AWS BEDROCK CREDENTIALS ==========
AWS_REGION=us-east-1
BEDROCK_ACCESS_KEY=your_aws_access_key_here
BEDROCK_SECRET_KEY=your_aws_secret_key_here

# ========== CHUNKING CONFIG ==========
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# ========== LOGGING & DEBUG ==========
LOG_LEVEL=INFO                  # Options: DEBUG, INFO, WARNING, ERROR

# ========== OPTIONAL CONFIG ==========
CACHE_EMBEDDINGS=True
MAX_DOCS_TO_LOAD=200            # Limit number of PDFs or chunks to load
DOC_LANGUAGE=en                 # Useful if multilingual_

